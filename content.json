{"meta":{"title":"linjunhua's Blog","subtitle":"","description":"","author":"linlinnn","url":"https://github.com/linlinnn","root":"/"},"pages":[{"title":"Tags","date":"2020-01-19T16:29:03.090Z","updated":"2020-01-19T16:29:03.090Z","comments":true,"path":"tags/index.html","permalink":"https://github.com/linlinnn/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-01-11T14:37:31.000Z","updated":"2020-01-11T14:37:31.921Z","comments":true,"path":"categories/index.html","permalink":"https://github.com/linlinnn/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2020-01-18T12:56:07.352Z","updated":"2020-01-18T12:56:07.352Z","comments":true,"path":"about/index.html","permalink":"https://github.com/linlinnn/about/index.html","excerpt":"","text":""},{"title":"Project","date":"2020-01-18T12:56:07.380Z","updated":"2020-01-18T12:56:07.380Z","comments":true,"path":"project/index.html","permalink":"https://github.com/linlinnn/project/index.html","excerpt":"","text":""}],"posts":[{"title":"Java源码之HashMap","slug":"Java源码之HashMap","date":"2020-02-26T07:51:41.426Z","updated":"2020-02-26T16:02:34.963Z","comments":true,"path":"2020/02/26/Java源码之HashMap/","link":"","permalink":"https://github.com/linlinnn/2020/02/26/Java%E6%BA%90%E7%A0%81%E4%B9%8BHashMap/","excerpt":"","text":"Java源码之HashMap1、带着问题看源码Q1：江湖规矩，请问HashMap是线程安全的吗？为什么线程不安全？ Q2：JDK1.7和1.8的HashMap有哪些区别？ Q3：如何解决Hash冲突解决？ Q4：动态扩容的策略是什么？ 2、数据存储结构先从1.8的看起，HashMap底层的数据结构是数组+链表+红黑树 显然最突出就是一个链表和红黑树的转换 12345678910111213141516171819202122// 默认的HashMap的空间大小16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// hashMap最大的空间大小static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// HashMap默认负载因子，负载因子越小，hash冲突机率越低，至于为什么，看完下面源码就知道了static final float DEFAULT_LOAD_FACTOR = 0.75f;// 链表长度大于等于8时，链表转化成红黑树static final int TREEIFY_THRESHOLD = 8;// 红黑树大小小于等于6时，红黑树转化成链表static final int UNTREEIFY_THRESHOLD = 6;// 当数组容量大于 64 时，链表才会转化成红黑树static final int MIN_TREEIFY_CAPACITY = 64;// 存放数据的数组transient Node&lt;K,V&gt;[] table;// 临界值（超过这个值则开始扩容）int threshold;// HashMap 负载因子final float loadFactor;// 链表的节点static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt;// 红黑树的节点static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; 3、初始化有四种初始化方法，指定初始容量和负载因子，指定初始容量，无参，指定数据集合 12345678910111213141516171819202122232425262728293031323334353637public HashMap(int initialCapacity, float loadFactor) &#123; // 边界值判断 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; // 根据初始容量计算扩容临界值，&gt;=initialCapacity的2的最小的幂次方 this.threshold = tableSizeFor(initialCapacity);&#125;// 注意这里没有32位的移动，因为最大容量MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 4、添加元素12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;static final int hash(Object key) &#123; int h; // key为null返回0，反则hash码后与自身高16位进行异或 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // tab:哈希表，n:哈希表的长度，i:散列后落到哈希表的索引，p：索引i对应的节点 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果哈希表为空，进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果节点为空，直接设为新节点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 旧节点和新节点哈希值和key都相同 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 节点p是一个红黑树节点，按照红黑树的方式设置 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 是一个链表 for (int binCount = 0; ; ++binCount) &#123; // 遍历链表至末尾 if ((e = p.next) == null) &#123; // 新节点插入到链表尾部 p.next = newNode(hash, key, value, null); // 链表长度超过阈值8的话，转换成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 循环过程中遇到一个与新节点相同的节点，退出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // e不为空代表有一个节点哈希值和key都和新节点相同 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // 如果不是putIfAbsent或者旧值为空，替换为新值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 哈希表超过扩容阈值，进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; ​ 红黑树是一种平衡二叉查找树，查询效率为O(logn) ​ 为什么大于等于8要进行链表到红黑树的转换，注释上大佬有说，因为正常情况下有8个哈希值冲突的概率是0.00000006，更多的话就小于千万分之一，一般根本不会发生，如果发生了的话就是散列函数出了问题，在这种情况下，红黑树作为一种查询性能较高的数据结构作为兜底，维持到O(logn) 5、动态扩容1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; // oldCapacity:旧哈希表的大小 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 扩容阈值 int oldThr = threshold; // newCapacity:新哈希表的大小，newThreshold:新的扩容阈值，大佬是不喜欢长命名么。。 int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 旧哈希表大小 &gt;= 2^30，直接到顶INT_MAX if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 新哈希表大小 * 2 &lt; 2^30 且 旧哈希表大小 &gt;= 16 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 扩容阈值 * 2 newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 旧哈希表大小为0，旧扩容阈值&gt;0，初始化为旧扩容阈值 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 旧哈希表大小为0，旧扩容阈值为0，初始化为默认值 newCap = DEFAULT_INITIAL_CAPACITY; //16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); // 16*0.75=12 &#125; // 新扩容阈值为0 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; // 容量*负载因子 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 将旧的哈希表元素重新散列到新的哈希表 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 扩容策略是当哈希表中的元素个数大于哈希表大小 * 负载因子，哈希表大小*2，乘2很好理解，因为保持了2的幂次方，可以看到扩容后需要对原来的元素进行重新散列，这个过程是非常消耗性能的。 负载因子默认为0.75，哈希表默认大小为16，当插入第13个元素时，哈希表扩容至32。 负载因子越大，空间利用率越高，哈希冲突可能性也越大，所以0.75是这两者考量之下折中的值，并且在这个情况下，哈希冲突同一位置超过8个的概率已经低于千万分之一了 6、对比JDK1.7123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 共享的空Mapstatic final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;// table就是HashMap实际存储数组的地方transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;public V put(K key, V value) &#123; // 当插入第一个元素的时候，需要先初始化数组大小 if (table == EMPTY_TABLE) &#123; // 数组初始化 inflateTable(threshold); &#125; // 如果key为null，将这个entry放到table[0]中 if (key == null) return putForNullKey(value); // 1. 求key的hash值，进行了多次异或，由于边际效应并不高，1.8只对高16位异或一次 int hash = hash(key); // 2. 找到对应的数组下标 int i = indexFor(hash, table.length); // 3. 遍历一下对应下标处的链表，看是否有重复的key已经存在，如果有，直接覆盖，put方法返回旧值就结束了 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; // key -&gt; value V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 4. 不存在重复的key，将此 entry 添加到链表中 addEntry(hash, key, value, i); return null;&#125;void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 如果当前HashMap大小已经达到了阈值，并且新值要插入的数组位置已经有元素了，那么要扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; // 扩容，容量 * 2 resize(2 * table.length); // 扩容以后，重新计算 hash 值 hash = (null != key) ? hash(key) : 0; // 重新计算扩容后的新的下标 bucketIndex = indexFor(hash, table.length); &#125; // 创建元素 createEntry(hash, key, value, bucketIndex);&#125;// 头插法，将新值放到链表的表头，然后size++void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K, V&gt; e = table[bucketIndex]; // 新节点.next = e table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125;void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; // 如果之前的HashMap已经扩充到最大了，那么就将临界值threshold设置为最大的int值 if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 新的数组 Entry[] newTable = new Entry[newCapacity]; // 将原来数组中的值迁移到新的更大的数组中 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; // 阈值计算 threshold = (int) Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;","categories":[],"tags":[{"name":"Java源码","slug":"Java源码","permalink":"https://github.com/linlinnn/tags/Java%E6%BA%90%E7%A0%81/"}]},{"title":"Java源码之LinkedList","slug":"Java源码之LinkedList","date":"2020-02-26T02:49:24.803Z","updated":"2020-02-26T07:40:41.854Z","comments":true,"path":"2020/02/26/Java源码之LinkedList/","link":"","permalink":"https://github.com/linlinnn/2020/02/26/Java%E6%BA%90%E7%A0%81%E4%B9%8BLinkedList/","excerpt":"","text":"Java源码之LinkedList1、带着问题看源码Q1：添加、删除、查找、遍历操作相应操作的原理是什么，时间复杂度是多少？ Q2：跟ArrayList的对比？ Q3：序列化机制？ 2、数据存储结构LinkedList的数据存储结构是一个双向链表 123456789101112131415transient int size = 0;transient Node&lt;E&gt; first; // 指向第一个节点transient Node&lt;E&gt; last; // 指向最后一个节点// 节点private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; // 指向下一个节点 Node&lt;E&gt; prev; // 指向上一个节点 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; size表示当前链表的节点数，显然可以根据size将链表分成两半，靠近首部就从first开始遍历，靠近尾部就从last开始遍历 3、初始化有两种初始化方法，无参初始化，指定数据集合初始化 1234567public LinkedList() &#123;&#125;public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 4、添加元素1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public boolean add(E e) &#123; // 在尾部添加一个元素 linkLast(e); return true;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; // 最后一个节点为空，即first节点=last节点 if (l == null) first = newNode; // 添加到最后一个节点的后面 else l.next = newNode; size++; modCount++;&#125;// index表示第一个元素插入的位置public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; // 边界检查是否在[0,size] checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; // 添加元素集合长度为0，直接返回false if (numNew == 0) return false; Node&lt;E&gt; pred, succ; // 前驱节点、后继节点 // 在链尾添加，前驱节点为last节点 if (index == size) &#123; succ = null; pred = last; &#125; else &#123; // 否则，后继节点为index位置所在的节点 succ = node(index); pred = succ.prev; &#125; // 遍历集合插入元素到前驱节点的后面 for (Object o : a) &#123; @SuppressWarnings(\"unchecked\") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); // 前驱节点为null,插入到链表首部 if (pred == null) first = newNode; // 否则，插入到前驱节点的后面 else pred.next = newNode; // 更新前驱节点 pred = newNode; &#125; // 连接后继节点 // 后继节点为空，即前驱节点为最后一个节点 if (succ == null) &#123; last = pred; &#125; else &#123; // 否则，连接在一起 pred.next = succ; succ.prev = pred; &#125; // 同步链表长度 size += numNew; modCount++; // 修改计数只+1 return true;&#125; 链表操作，边界情况需要仔细考虑，主要考虑头和尾，比如addAll 的逻辑如下 找到index位置对应的前驱节点和后继节点 1.1. 插入到链表尾部，后继节点为null 1.2. 插入到链表头部，前驱节点为null 1.3. 插入到链表中间，后继节点为index节点 将元素集合依次连接在前驱节点的后面 需要考虑1.2这种情况，前驱节点为null，即最后一个新增元素为first节点，然后依次连接 最后一个新增元素与后继节点相连 需要考虑1.1这种情况，后继节点为null，即最后一个新增元素为last节点 5、删除元素1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 删除头节点private E unlinkFirst(Node&lt;E&gt; f) &#123; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC // 更新头节点为下一个节点 first = next; // 链表只剩一个节点，删除后，first = last = null if (next == null) last = null; // 头节点的prev设为null else next.prev = null; size--; modCount++; return element;&#125;// 删除最后一个节点private E unlinkLast(Node&lt;E&gt; l) &#123; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC // 更新头节点为上一个节点 last = prev; // 链表只剩一个节点，删除后，first = last = null if (prev == null) first = null; // 尾节点的next设为null else prev.next = null; size--; modCount++; return element;&#125;// 删除一个非空节点E unlink(Node&lt;E&gt; x) &#123; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // 和前驱节点断开，考虑删除是不是头节点 if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; // 和后继节点断开，考虑删除是不是尾节点 if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; // 此时该节点的prev、item、next都设为了null size--; modCount++; return element;&#125; 6、查询元素1234567891011121314Node&lt;E&gt; node(int index) &#123; // index位于链表的左半部分，从first开始遍历 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 7、序列化机制12345678910111213141516171819private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; s.defaultWriteObject(); s.writeInt(size); // 按顺序序列化数据 for (Node&lt;E&gt; x = first; x != null; x = x.next) s.writeObject(x.item);&#125;@SuppressWarnings(\"unchecked\")private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); int size = s.readInt(); // 将数据进行反序列化构建链表 for (int i = 0; i &lt; size; i++) linkLast((E)s.readObject());&#125; 8、总结Q1：添加、删除、查找、遍历操作相应操作的原理是什么，时间复杂度是多少？ ​ 添加/删除元素，时间复杂度与位置相关，越靠近头节点或者尾节点，则趋向或等于O(1)，最差就是在中间位置，需要遍历n/2的长度，查找同理；所以遍历需要注意的是要使用迭代器依次顺序遍历，否则如果使用下标随机访问，则每次都要从头节点或者尾结点遍历一遍，大大降低性能。 Q2：跟ArrayList的对比？ 一个是数组结构，一个是双向链表； ArrayList添加数据空间不够时需要动态扩容，LinkedList只需要将数据串联起来 都可以进行随机访问，但是ArrayList才适合，性能比LinkedList高得多 不能笼统地认为插入删除就链表快，查询遍历就数组快，还要考虑具体的位置 把数据插入到头部，LinkedList很快就找到位置并串联起来，但是ArrayList要将元素后移，所以LinkedList快，数据位置越靠近中间LinkedList效率就越差。 把数据插入到尾部，ArrayList需要分情况讨论，不需要扩容的情况下是效率是很高的，因为不用复制移动元素，相比而言LinkedList定位尾部很快，不过需要new对象和指针串连，效率慢了一点，删除同理 查询的话主要是LinkedList不适合随机访问，顺序访问的前提下两者相差不大，ArrayList稍稍占优 Q3：序列化机制？ ​ 双向链表方便于往前和往后遍历，不过也需要花费前驱节点、后继节点这些指针定位空间，而我们真正需要的只是具有顺序性的数据，所以序列化时免去了指针这些不必要的浪费，然后反序列化重新构建链表","categories":[],"tags":[{"name":"Java源码","slug":"Java源码","permalink":"https://github.com/linlinnn/tags/Java%E6%BA%90%E7%A0%81/"}]},{"title":"Java源码之ArrayList","slug":"Java源码之ArrayList","date":"2020-02-25T01:14:10.654Z","updated":"2020-02-26T02:48:40.360Z","comments":true,"path":"2020/02/25/Java源码之ArrayList/","link":"","permalink":"https://github.com/linlinnn/2020/02/25/Java%E6%BA%90%E7%A0%81%E4%B9%8BArrayList/","excerpt":"","text":"Java源码之ArrayList1、带着问题看源码Q1：添加、查找、遍历操作最为普遍，相应操作的原理是什么，时间复杂度是多少？ Q2：如何进行动态扩展的？ Q3：序列化机制是怎样的？ 2、数据存储结构ArrayList在日常工作中非常常用，底层结构就是一个数组 12345678private static final int DEFAULT_CAPACITY = 10;private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;transient Object[] elementData; // non-private to simplify nested class accessprivate int size; 1、DEFAULT_CAPACITY，初始大小为10 2、EMPTY_ELEMENTDATA 和DEFAULTCAPACITY_EMPTY_ELEMENTDATA 的区别在于添加第一个元素时的扩容策略 3、elementData使用transient修饰，比如一个100万大小的数组，只存储了100个数据，那么只序列化这100个就好了，避免浪费不必要的资源，使用writeObject和readObject进行序列化 3、初始化有三种初始化方法：指定大小初始化，无参初始化，指定数据集合初始化 12345678910111213141516171819202122232425262728293031public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; // 创建一个指定大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 返回静态的空数组EMPTY_ELEMENTDATA this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; // 初始大小为负数，抛出异常 throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125;&#125;public ArrayList() &#123; // 返回静态的空数组DEFAULTCAPACITY_EMPTY_ELEMENTDATA，在添加第一个元素后大小才为10 this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) // 如果集合元素类型不是Object，转换成Object类型，Q4：为什么？ if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 返回静态的空数组EMPTY_ELEMENTDATA this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; Q4的测试代码如下，转换是为了防止数组元素赋值时发生类型错误 123456List&lt;String&gt; list = Arrays.asList(\"hello,ArrayList\");Object[] arr = list.toArray();System.out.println(arr.getClass().getSimpleName()); // String[]arr[0] = new Object();// java.lang.ArrayStoreException 4、添加元素1234567891011121314151617181920212223242526272829303132333435363738public boolean add(E e) &#123; // 确保数组容量大小，不够时执行扩容 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // 如果是静态空数组DEFAULTCAPACITY_EMPTY_ELEMENTDATA，在minCapacity和默认大小10取最大值 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 当前数组大小小于期望大小，数组需要扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; int oldCapacity = elementData.length; // 扩容加上原来的一半大小，即原来的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 加上一半还是不够大的话就直接扩至期望大小 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 准备扩容大小超过的INT_MAX - 8 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) // 为负时说明超出了INT的范围，抛出OutOfMemoryError异常 // 否则MAX_ARRAY_SIZE刚好则为MAX_ARRAY_SIZE，还不够就INT_MAX newCapacity = hugeCapacity(minCapacity); // 将原数组拷贝到新的数组 elementData = Arrays.copyOf(elementData, newCapacity);&#125; 5、删除元素12345678910111213141516171819202122232425public E remove(int index) &#123; // 数组边界检查，只对上限做了检查 rangeCheck(index); // 修改计数+1 modCount++; E oldValue = elementData(index); // 把删除的元素以后的元素向前移动 int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125;// Checks if the given index is in range. If not, throws an appropriate runtime exception.private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; ​ 这里值得注意的是rangeCheck和rangeCheckForAdd 的区别，函数的意义决定了函数的职责边界，从而对应内部的实现，如rangeCheck 是get、remove、set方法操作已存在元素的，所以只检查上边界，下边界检查的职责交给数组的访问，而rangeCheckForAdd 是add、addAll操作未存在元素的，所以检查上下边界。 6、迭代器的remove和ArrayList的remove123456789101112131415161718192021222324252627282930public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; // 同步期望计数 expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125;&#125;// 修改计数和期望计数不相同，抛出异常final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125;private void fastRemove(int index) &#123; // 修改计数+1，后续没有进行同步期望计数，在遍历过程中会抛出ConcurrentModificationException modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 遍历删除元素时两种方法比较 通过迭代器Iterator#remove方法不会报错，而forEach调用至fastRemove由于没有同步期望计数，会抛出ConcurrentModificationException 所以这两个remove方法有一定的偏向性，即ArrayList的remove应该用于删除单个元素的场景 7、序列化机制12345678910111213141516171819202122232425262728293031323334353637383940414243private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; int expectedModCount = modCount; // 序列化non-static和non-transient的数据 s.defaultWriteObject(); // Q5:为什么这里还要write一次size呢？ // 这是为了版本兼容，老版本根据size这个成员变量去申请对应空间 // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // 序列化数组元素 for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125;private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125; 8、总结Q1：添加、查找、遍历操作最为普遍，相应操作的原理是什么，时间复杂度是多少？ ​ 添加/删除操作，需要考虑具体的位置，在数组开头，需要移动元素，时间复杂度是O(n)，在数组尾部，时间复杂度是O(1)，遍历查找无序数组中的一个元素时间复杂度为O(n) Q2：如何进行动态扩展的？ ​ 当数组空间不足时进行动态扩展，扩展到原数组的1.5倍大小，仍不够的话扩展到期望大小（这种情况是初始化大小为10时或者addAll时发生），最多扩展至INT_MAX Q3：序列化机制是怎样的？ ​ 保存元素的element数组使用transient修饰，是避免序列化没有存储数据的空间提升性能，使用定制化的writeObject序列化和readObject反序列化","categories":[],"tags":[{"name":"Java源码","slug":"Java源码","permalink":"https://github.com/linlinnn/tags/Java%E6%BA%90%E7%A0%81/"}]},{"title":"Dubbo扩展点加载机制","slug":"dubbo扩展点","date":"2020-01-11T16:23:25.855Z","updated":"2020-01-19T13:42:15.643Z","comments":true,"path":"2020/01/12/dubbo扩展点/","link":"","permalink":"https://github.com/linlinnn/2020/01/12/dubbo%E6%89%A9%E5%B1%95%E7%82%B9/","excerpt":"","text":"Dubbo扩展点加载机制1、Java SPI使用了策略模式，一个接口多种实现。只声明接口，具体的实现由程序之外的配置控制，用于具体实现的装配。 具体步骤如下： （1）定义一个接口以及对应的方法 （2）编写接口的实现类 （3）在META-INF/services/ 目录下，创建一个接口全限定名命名的文件 （4）文件内容为具体实现类的全限定名，如果有多个，则用分行符分隔 （5）在代码中通过java.util.ServiceLoader 来加载具体的实现类 2、扩展点加载机制的改进 初始化 JDK SPI: 一次性实例化扩展点所有实现，初始化耗时，没有也加载浪费资源 Dubbo SPI: 加载配置文件中的类，并分为不同的种类缓存在内存中，不会立即全部初始化 扩展点加载失败 JDK SPI: 获取不到扩展的名称，不能打印正常的异常信息 Dubbo SPI: 抛出真实异常并打印日志，部分扩展点加载失败不会影响其他扩展点和整个框架的使用 实现了IOC和AOP机制 3、扩展点的配置规范 规范名 规范说明 SPI配置文件路径 META-INF/services/、META-INF/dubbo/、META-INF/dubbo/internal/ 全路径类名 文件内容格式 key=value方式，多个用换行符分隔 4、扩展点的分类与缓存Dubbo SPI Class缓存：Dubbo SPI获取扩展类时，先从缓存中读取。如果缓存中不存在，则加载配置文件，根据配置把Class缓存到内存中，不会直接初始化 实例缓存：基于性能考虑，Dubbo框架不仅会缓存Class，也会缓存Class实例化对象。先从缓存中读取，如果缓存中不存在，则重新加载并缓存起来，按需实例化并缓存 扩展类种类 普通扩展类 包装扩展类：Wrapper类没有具体的实现，只是做了通用逻辑的抽象，在构造方法中传入一个具体的扩展接口的实现 自适应扩展类：一个扩展接口有多种实现类，具体实现哪个实现类可以不写死在配置或代码中，在运行时，通过传入URL中的某些参数动态来确定。自适应特性@Adaptive 其他缓存 自适应和自动激活的区别？ isAssignableFrom 和 instanceof 的区别？ 123父类.class.isAssignableFrom(子类.class)子类实例 instanceof 父类类型","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://github.com/linlinnn/tags/Dubbo/"}]}]}